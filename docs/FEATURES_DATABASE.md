# âœ¨ Features: SQLite Database for User Web Activity

> **Goal:** Create a SQLite database stored locally on the user's computer to securely store user web activity data including cookies, web history, and time spent on sites.

---

## ğŸ“‹ Overview

This document outlines the step-by-step plan for designing, implementing, and deploying a **SQLite database** to power DataForge's user web activity tracking system. The database will be **hosted locally on the user's computer**, ensuring maximum privacy, offline-first functionality, and complete user control over their data.

### Why SQLite?

| Benefit | Description |
|---------|-------------|
| ğŸ” **Privacy-First** | Data never leaves the user's device unless explicitly shared |
| ğŸ“´ **Offline Support** | Full functionality without internet connection |
| âš¡ **Performance** | Zero network latency for read/write operations |
| ğŸ¯ **Simplicity** | No server setup or maintenance required |
| ğŸ’¾ **Portable** | Single file database, easy to backup/migrate |
| ğŸ‘¤ **User Control** | Users own and control their data completely |

---

## ğŸ—‚ï¸ Data Categories

The database will store three primary categories of user web activity:

| Category | Description | Example Data |
|----------|-------------|--------------|
| ğŸª **Cookies** | Browser cookies collected with user consent | Cookie name, value, domain, expiration, type |
| ğŸŒ **Web History** | URLs visited by the user | URL, page title, visit timestamp, referrer |
| â±ï¸ **Time Spent** | Duration of time spent on websites | Domain, session duration, active time, scroll depth |

---

## ğŸš€ Implementation Plan

### Phase 1: Database Design & Schema

#### Step 1.1: Define Core Tables

Design the foundational database schema with the following tables:

| Table Name | Purpose |
|------------|---------|
| `users` | Store user account information and preferences |
| `sessions` | Track browsing sessions for each user |
| `cookies` | Store cookie data with consent tracking |
| `web_history` | Log visited URLs and page metadata |
| `time_spent` | Track engagement metrics per site |
| `consent_log` | Audit trail for user data sharing preferences |

#### Step 1.2: Define Relationships

```
users (1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< (âˆ) sessions
              â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< (âˆ) cookies
              â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< (âˆ) web_history
              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< (âˆ) time_spent
```

#### Step 1.3: Design Table Schemas

**`users` Table:**
```sql
CREATE TABLE users (
    user_id         TEXT PRIMARY KEY,  -- UUID generated by application
    email           TEXT UNIQUE NOT NULL,
    created_at      TEXT DEFAULT (datetime('now')),
    updated_at      TEXT DEFAULT (datetime('now')),
    consent_status  INTEGER DEFAULT 0,  -- 0=false, 1=true
    data_sharing    TEXT DEFAULT '{}'   -- JSON stored as text
);
```

**`sessions` Table:**
```sql
CREATE TABLE sessions (
    session_id      TEXT PRIMARY KEY,  -- UUID generated by application
    user_id         TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    started_at      TEXT DEFAULT (datetime('now')),
    ended_at        TEXT,
    device_type     TEXT,
    browser         TEXT,
    os              TEXT
);
```

**`cookies` Table:**
```sql
CREATE TABLE cookies (
    cookie_id       TEXT PRIMARY KEY,  -- UUID generated by application
    user_id         TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    session_id      TEXT REFERENCES sessions(session_id),
    domain          TEXT NOT NULL,
    cookie_name     TEXT NOT NULL,
    cookie_value    TEXT,
    cookie_type     TEXT,  -- 'first_party', 'third_party', 'tracking', etc.
    expiration      TEXT,
    is_secure       INTEGER DEFAULT 0,  -- 0=false, 1=true
    is_http_only    INTEGER DEFAULT 0,  -- 0=false, 1=true
    collected_at    TEXT DEFAULT (datetime('now'))
);
```

**`web_history` Table:**
```sql
CREATE TABLE web_history (
    history_id      TEXT PRIMARY KEY,  -- UUID generated by application
    user_id         TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    session_id      TEXT REFERENCES sessions(session_id),
    url             TEXT NOT NULL,
    domain          TEXT NOT NULL,
    page_title      TEXT,
    referrer_url    TEXT,
    visited_at      TEXT DEFAULT (datetime('now')),
    visit_type      TEXT  -- 'link', 'typed', 'reload', 'back_forward'
);
```

**`time_spent` Table:**
```sql
CREATE TABLE time_spent (
    time_id             TEXT PRIMARY KEY,  -- UUID generated by application
    user_id             TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    session_id          TEXT REFERENCES sessions(session_id),
    history_id          TEXT REFERENCES web_history(history_id),
    domain              TEXT NOT NULL,
    url                 TEXT NOT NULL,
    duration_seconds    INTEGER NOT NULL,
    active_seconds      INTEGER,  -- Time user was actively engaged
    scroll_depth        REAL,     -- Percentage of page scrolled
    started_at          TEXT NOT NULL,
    ended_at            TEXT
);
```

**`consent_log` Table:**
```sql
CREATE TABLE consent_log (
    log_id          TEXT PRIMARY KEY,  -- UUID generated by application
    user_id         TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    consent_type    TEXT NOT NULL,
    consent_given   INTEGER NOT NULL,  -- 0=false, 1=true
    ip_address      TEXT,
    user_agent      TEXT,
    created_at      TEXT DEFAULT (datetime('now'))
);
```

---

### Phase 2: Indexing & Optimization

#### Step 2.1: Create Performance Indexes

```sql
-- User lookups
CREATE INDEX idx_users_email ON users(email);

-- Session queries
CREATE INDEX idx_sessions_user_id ON sessions(user_id);
CREATE INDEX idx_sessions_started_at ON sessions(started_at);

-- Cookie queries
CREATE INDEX idx_cookies_user_id ON cookies(user_id);
CREATE INDEX idx_cookies_domain ON cookies(domain);
CREATE INDEX idx_cookies_collected_at ON cookies(collected_at);

-- Web history queries (most frequent)
CREATE INDEX idx_web_history_user_id ON web_history(user_id);
CREATE INDEX idx_web_history_domain ON web_history(domain);
CREATE INDEX idx_web_history_visited_at ON web_history(visited_at);
CREATE INDEX idx_web_history_user_domain ON web_history(user_id, domain);

-- Time spent queries
CREATE INDEX idx_time_spent_user_id ON time_spent(user_id);
CREATE INDEX idx_time_spent_domain ON time_spent(domain);
CREATE INDEX idx_time_spent_started_at ON time_spent(started_at);
```

#### Step 2.2: Data Management Strategy

SQLite doesn't support native table partitioning. For managing large datasets:

**Option A: Archive Old Data**
```sql
-- Move old data to archive table periodically (handled by application)
INSERT INTO web_history_archive SELECT * FROM web_history 
WHERE datetime(visited_at) < datetime('now', '-6 months');

DELETE FROM web_history 
WHERE datetime(visited_at) < datetime('now', '-6 months');
```

**Option B: Separate Database Files**
For very active users, consider using separate SQLite database files by time period (e.g., `dataforge_2026.db`).

---

### Phase 3: Security & Privacy

#### Step 3.1: Local Data Isolation

Since the database is stored locally on the user's computer, security focuses on file-level protection:

```sql
-- Enable foreign key enforcement (SQLite requires this)
PRAGMA foreign_keys = ON;

-- Ensure data integrity
PRAGMA integrity_check;
```

> **Note:** Row-Level Security is not needed for local storage since all data belongs to a single user. The local SQLite database is inherently isolated.

#### Step 3.2: Data Encryption

- [ ] Use SQLCipher or similar for database file encryption (optional, based on user preference)
- [ ] Store encryption key securely using OS-level keychain (Windows Credential Manager, macOS Keychain)
- [ ] Encrypt sensitive fields at application level before storage

#### Step 3.3: Data Retention Policies

The application will handle data cleanup since SQLite doesn't support scheduled functions:

```sql
-- Data cleanup queries (executed by application on schedule)
-- Delete data older than 90 days (configurable per user preference)
DELETE FROM web_history WHERE datetime(visited_at) < datetime('now', '-90 days');
DELETE FROM cookies WHERE datetime(collected_at) < datetime('now', '-90 days');
DELETE FROM time_spent WHERE datetime(started_at) < datetime('now', '-90 days');
```

#### Step 3.4: Optional Cloud Sync

When users consent to share data:

- [ ] Implement selective sync to cloud PostgreSQL for AI training
- [ ] Anonymize/aggregate data before upload
- [ ] Provide transparency on what data is shared
- [ ] Allow one-click data deletion from cloud

---

### Phase 4: Local Deployment

#### Step 4.1: Database Location

The SQLite database file will be stored in a platform-appropriate location:

| Platform | Default Location |
|----------|-----------------|
| Windows | `%APPDATA%\DataForge\dataforge.db` |
| macOS | `~/Library/Application Support/DataForge/dataforge.db` |
| Linux | `~/.local/share/DataForge/dataforge.db` |

#### Step 4.2: Database Initialization

```javascript
// Example: Database initialization on app startup
const sqlite3 = require('better-sqlite3');
const path = require('path');
const os = require('os');

function getDbPath() {
    const appName = 'DataForge';
    switch (process.platform) {
        case 'win32':
            return path.join(process.env.APPDATA, appName, 'dataforge.db');
        case 'darwin':
            return path.join(os.homedir(), 'Library', 'Application Support', appName, 'dataforge.db');
        default:
            return path.join(os.homedir(), '.local', 'share', appName, 'dataforge.db');
    }
}

const db = new sqlite3(getDbPath());
db.pragma('journal_mode = WAL');  // Better performance for concurrent reads
db.pragma('foreign_keys = ON');
```

#### Step 4.3: Backup & Export

- [ ] Implement automatic local backups (configurable frequency)
- [ ] Allow users to export their data (JSON, CSV formats)
- [ ] Support database migration for app updates
- [ ] Provide data import functionality for device transfers

---

### Phase 5: API Integration Layer

#### Step 5.1: Database Access Patterns

Design efficient queries for common operations:

| Operation | Query Pattern |
|-----------|---------------|
| Insert web visit | Single INSERT into `web_history` |
| Batch insert cookies | Bulk INSERT with `INSERT OR REPLACE` |
| Get user history | SELECT with `LIMIT` and `OFFSET` for pagination |
| Aggregate time spent | GROUP BY domain with SUM |

#### Step 5.2: Extension/App Communication

- [ ] Use IPC (Inter-Process Communication) between Chrome Extension and Desktop App
- [ ] Desktop app manages sole connection to SQLite database
- [ ] Implement message queue for buffering writes during high activity
- [ ] Handle concurrent read requests efficiently (WAL mode enables this)

---

### Phase 6: Analytics Views (For AI Assistant)

#### Step 6.1: Create Views

SQLite doesn't support materialized views, but we can use regular views for queries and summary tables for performance:

```sql
-- Daily domain visits view
CREATE VIEW v_daily_domain_visits AS
SELECT 
    user_id,
    domain,
    DATE(visited_at) as visit_date,
    COUNT(*) as visit_count
FROM web_history
GROUP BY user_id, domain, DATE(visited_at);

-- User engagement summary view
CREATE VIEW v_user_engagement AS
SELECT 
    user_id,
    domain,
    SUM(duration_seconds) as total_time,
    AVG(scroll_depth) as avg_scroll_depth,
    COUNT(*) as visit_count
FROM time_spent
GROUP BY user_id, domain;
```

#### Step 6.2: Summary Tables (For Performance)

For frequently accessed analytics, maintain summary tables updated by the application:

```sql
-- Pre-computed daily summaries for faster dashboard loading
CREATE TABLE daily_summary (
    summary_id      TEXT PRIMARY KEY,
    user_id         TEXT REFERENCES users(user_id) ON DELETE CASCADE,
    summary_date    TEXT NOT NULL,
    total_visits    INTEGER DEFAULT 0,
    total_time      INTEGER DEFAULT 0,
    unique_domains  INTEGER DEFAULT 0,
    updated_at      TEXT DEFAULT (datetime('now')),
    UNIQUE(user_id, summary_date)
);
```

#### Step 6.3: Data Export for Cloud AI

When user opts to share data for AI insights:

```sql
-- Query to extract anonymized data for cloud sync
SELECT 
    domain,
    DATE(visited_at) as visit_date,
    COUNT(*) as visit_count,
    SUM(duration_seconds) as total_time
FROM web_history w
JOIN time_spent t ON w.history_id = t.history_id
GROUP BY domain, DATE(visited_at);
```

---

## âœ… Implementation Checklist

### Phase 1: Database Design
- [ ] Finalize table schemas (SQLite compatible)
- [ ] Review relationships and constraints
- [ ] Validate data types for all fields
- [ ] Test UUID generation in application layer

### Phase 2: Optimization
- [ ] Create all necessary indexes
- [ ] Configure WAL mode for concurrent access
- [ ] Test query performance with sample data

### Phase 3: Security
- [ ] Implement file-level encryption (optional SQLCipher)
- [ ] Configure data retention policies
- [ ] Set up consent tracking
- [ ] Build optional cloud sync mechanism

### Phase 4: Local Deployment
- [ ] Implement platform-specific database paths
- [ ] Create database initialization on first run
- [ ] Set up automatic backup system
- [ ] Build data export/import functionality

### Phase 5: Integration
- [ ] Design IPC between Extension and Desktop App
- [ ] Implement write buffering for high activity
- [ ] Test from Chrome Extension/Desktop App

### Phase 6: Analytics
- [ ] Create views for common queries
- [ ] Build summary tables for dashboard
- [ ] Implement data export for cloud AI (with consent)

---

## ğŸ“… Estimated Timeline

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| Phase 1: Design | 2-3 days | - |
| Phase 2: Optimization | 1-2 days | Phase 1 |
| Phase 3: Security | 2-3 days | Phase 1 |
| Phase 4: Deployment | 1-2 days | Phase 1-3 |
| Phase 5: Integration | 3-5 days | Phase 4 |
| Phase 6: Analytics | 2-3 days | Phase 4 |

**Total Estimated Time:** 2-3 weeks

---

## ğŸ”— Related Documents

- [README.md](../README.md) - Project overview
- *API Documentation* - Coming soon
- *Chrome Extension Docs* - Coming soon

---

## ğŸ’¬ Questions for Review

1. **Data Retention:** How long should we retain user data locally by default? (Current plan: 90 days)
2. **Encryption:** Should we require database encryption by default, or make it optional?
3. **Cloud Sync:** What data should users be able to opt-in to share with the cloud AI?
4. **Additional Data Points:** Are there other web activity metrics we should capture?
5. **Compliance Requirements:** Any specific GDPR/CCPA requirements to consider for local storage?

---

*Last Updated: January 13, 2026*
